#!/usr/bin/env python

"""
Test our HAIS implementation on example 1a from http://arxiv.org/abs/1205.1925

We name the latent variable 'z' in place of 'a'

The code is set up to estimate the log marginal of several batches (different `x`) concurrently.

When the latent dimensionality, L, is around 5, there is still some considerable variance in the log marginal estimates.
"""


import tensorflow as tf
import numpy as np
from hais import ais, examples
import matplotlib.pyplot as plt
from matplotlib import lines
import seaborn as sns
import time
tfd = tf.contrib.distributions


#
# Jupyter magic
#
# %load_ext autoreload
# %autoreload 2


#
# Constants
#
# RNG seed
SEED = 41
#
# HMC AIS
N_ITER = 3000
N_CHAINS = 400
STEPSIZE = .025
ADAPT_STEPSIZE = False
#
# Model
BATCH_SIZE = 99  # number of distinct x
M = 36  # x dimensions
L = 3   # z dimensions
SIGMA_N = .1

#
# Seed RNGs
print('Seeding RNGs')
np.random.seed(SEED)
tf.set_random_seed(SEED)


#
# Model
print('Sampling model')
generative = examples.Culpepper1aGaussian(M, L, BATCH_SIZE, SIGMA_N)
phi, z, x_loc, px, x = generative.sample()
z_prior = generative.prior(N_CHAINS)
ll_fn = generative.log_likelihood_fn(tf.constant(
    x, dtype=tf.float32, name='x'), tf.constant(phi, dtype=tf.float32, name='phi'), N_CHAINS)


#
# Exact marginal likelihood
lp_exact = generative.log_marginal(x, phi)
print('Calculated exact marginal log likelihood(s): mean={:.1f}; sd={:.1f}'.format(
    np.mean(lp_exact), np.std(lp_exact)))


#
# Annealed importance sampling
print('Constructing AIS computation graph')
starttime = time.time()
model = ais.HAIS(prior=z_prior, log_likelihood=ll_fn, stepsize=STEPSIZE, adapt_stepsize=ADAPT_STEPSIZE)
#
# Set up an annealing schedule
schedule = ais.get_schedule(T=N_ITER, r=4)
#
# Set up the computation graph
logw, z_i, eps, smthd_acceptance_rate = model.ais(schedule)
#
# Calculate the log normalizer (aka log marginal), remember batches are in dimension 0, chains in dimension 1
log_normalizer = model.log_normalizer(logw, samples_axis=1)
endtime = time.time()
print('Constructing graph took {:.1g} seconds'.format(endtime - starttime))
#
# Construct and initialise the session
sess = tf.Session()
# merged = tf.summary.merge_all()
# summary_writer = tf.summary.FileWriter('logs')
sess.run(tf.global_variables_initializer())
#
# Run AIS
print('Running AIS')
starttime = time.time()
log_marginal, logw_ais, z_sampled, eps_final, final_smthd_acceptance_rate = \
    sess.run([log_normalizer, logw, z_i, eps, smthd_acceptance_rate])
endtime = time.time()
print('AIS took {:.1f} seconds'.format(endtime - starttime))
print('Estimated marginal log likelihood(s): mean={:.1f}; sd={:.1f}'.format(
    np.mean(log_marginal), np.std(log_marginal)))
print('True      marginal log likelihood(s): mean={:.1f}; sd={:.1f}'.format(
    np.mean(lp_exact), np.std(lp_exact)))
rho = np.corrcoef(log_marginal, lp_exact)[0, 1]
print('Correlation between estimates: {:.3f}'.format(rho))
print('Final step sizes: mean={:.3g}; sd={:.3g}'.format(
    np.mean(eps_final), np.std(eps_final)))
print('Final smoothed acceptance rate: mean={:.3f}; sd={:.3f}'.format(
    np.mean(final_smthd_acceptance_rate), np.std(final_smthd_acceptance_rate)))


#
# Plot the output
print('Plotting marginal log likelihoods')
if model.adapt_stepsize:
  fig, (ax, ax_accept, ax_stepsize) = plt.subplots(3, 1, figsize=(8, 12))
else:
  fig, (ax, ax_accept) = plt.subplots(2, 1, figsize=(8, 12))
ax.scatter(log_marginal, lp_exact)
ax.set_xlabel('AIS')
ax.set_ylabel('true')
ax.set_title('Marginal log likelihoods')
xmin, xmax = ax.get_xbound()
ymin, ymax = ax.get_ybound()
lower = max(xmin, ymin)
upper = min(xmax, ymax)
ax.add_line(lines.Line2D([lower, upper], [lower, upper], linestyle='dashed', color='k', alpha=.3))
#
# Acceptance rate
sns.distplot(final_smthd_acceptance_rate.flatten(), ax=ax_accept)
ax_accept.axvline(x=model.target_acceptance_rate, linestyle='dashed', color='k', alpha=.3)
ax_accept.set_title('average acceptance rates (per batch per chain)')
#
# Step sizes
if model.adapt_stepsize:
  sns.distplot(eps_final.flatten(), ax=ax_stepsize)
  ax_stepsize.axvline(x=model.stepsize, linestyle='dashed', color='k', alpha=.3)
  ax_stepsize.set_title('Step sizes (per batch per chain)')
#
fig.savefig('hais-model1a-gaussian.pdf')
